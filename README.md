# Did you consider how to monitor data integrity?

*[Data Stewardship Wizard] Question - additional resources*

Short UID: spg

## The Question

Working with large amounts of heterogenous data in a larger research group has implications for the data integrity. How do you make sure every step of the workflow is done with the right version of the data? How do you handle the situation when a mistake is uncovered? Will you be able to redo the strict minimum data handling?

### Possible answers:

  * Skip 
  * Explore 

## Links

  * [Resources page in DSW]
  * [Data Stewardship Wizard]
  * [DSW @ GitHub]


## Resources tips

  * If you have any ideas, please go to [issues].
  * You can provide any extra resources in the `/resources` directory via [pull request].

## Please contribute!

  * [Want to propose a new resource?](https://github.com/DSQResources/DSQ-spg/issues/new)
  * [Want to report an issue / give a feedback?](https://github.com/DSQResources/DSQ-spg/issues/new)
  * [We also welcome pull requests!](https://github.com/DSQResources/DSQ-spg/pulls)

----

*Do not edit this README file by hand, it is automatically generated*

[Data Stewardship Wizard]: https://dmp.fairdata.solutions
[Resources page in DSW]: https://dmp.fairdata.solutions/resources/spg
[DSW @ GitHub]: https://github.com/DataStewardshipWizard
[issues]: https://help.github.com/articles/about-issues/
[pull request]: https://help.github.com/articles/about-pull-requests/